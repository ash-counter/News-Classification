{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **News Category Classification using LSTM**\n",
    "**News categories included in this dataset include business; science and technology; entertainment; and health.** \n",
    "\n",
    "**Different news articles that refer to the same news item (e.g., several articles about recently released employment statistics) are also categorized together.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1  Fed official says weak data caused by weather,...   \n",
       "1   2  Fed's Charles Plosser sees high bar for change...   \n",
       "2   3  US open: Stocks fall after Fed official hints ...   \n",
       "3   4  Fed risks falling 'behind the curve', Charles ...   \n",
       "4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the dataset\n",
    "dir = pd.read_csv(\"/uci-news-aggregator.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "dir.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WE HAVE ONLY TWO FEATURES OF USE**\n",
    "\n",
    "1. **TITLE**\n",
    "2. **CATEGORY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE CATEGORY\n",
       "0  Fed official says weak data caused by weather,...        b\n",
       "1  Fed's Charles Plosser sees high bar for change...        b\n",
       "2  US open: Stocks fall after Fed official hints ...        b\n",
       "3  Fed risks falling 'behind the curve', Charles ...        b\n",
       "4  Fed's Plosser: Nasty Weather Has Curbed Job Gr...        b"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a new dataset with only relevant features.\n",
    "ds = dir[['TITLE','CATEGORY']]\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HERE YOU CAN SEE THAT ALL CATEGORIES ARE IN ORDER(ALL B's TOGETHER AND SO ON), THEREFORE SHUFFLING THEM FOR OUR CONVENIENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teen Arrested After Tweeting Bizarre Terrorist...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP Top News at 8:59 am EDT</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHO says fight against West Africa Ebola outbr...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FTC Accuses T-Mobile of Skimming Hundreds of M...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carrie Underwood and Miranda Lambert, plus mor...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE CATEGORY\n",
       "0  Teen Arrested After Tweeting Bizarre Terrorist...        e\n",
       "1                         AP Top News at 8:59 am EDT        e\n",
       "2  WHO says fight against West Africa Ebola outbr...        m\n",
       "3  FTC Accuses T-Mobile of Skimming Hundreds of M...        t\n",
       "4  Carrie Underwood and Miranda Lambert, plus mor...        e"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffling rows with the help of sample, here (frac = 1) means return all rows\n",
    "ds = ds.sample(frac=1).reset_index(drop=True)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASET IS NOW SHUFFLED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TITLE       0\n",
       "CATEGORY    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "ds.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**NO NULL VALUES FOUND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='CATEGORY', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plotting graph for categories\n",
    "sns.countplot(x = 'CATEGORY',data = ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THERE ARE FOUR TYPES OF CATEGORIES-**\n",
    "1. **b : business (~115000)**\n",
    "2. **t : science and technology (~110000)**\n",
    "3. **e : entertainment (~150000)**\n",
    "4. **m : health (~40000)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOW MOVING ONTO CLEANING AND PREPROCESSING OF THE TEXT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cleaning and preprocessing the text\n",
    "\n",
    "cleaned = []\n",
    "for i in range(0,len(ds)):\n",
    "    \n",
    "    #removing any other words than (a-z) and (A-Z)\n",
    "    msg = re.sub('[^a-zA-Z]',' ',ds['TITLE'][i])\n",
    "    \n",
    "    #converting all texts to lower case\n",
    "    msg = msg.lower()\n",
    "    \n",
    "    #tokenizing\n",
    "    msg = msg.split()\n",
    "    \n",
    "    #stemming and removing stopwords\n",
    "    ps = PorterStemmer()\n",
    "    msg = [ps.stem(words) for words in msg if not words in set(stopwords.words('english'))]\n",
    "    msg = ' '.join(msg)\n",
    "    cleaned.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['teen arrest tweet bizarr terrorist threat american airlin',\n",
       " 'ap top news edt',\n",
       " 'say fight west africa ebola outbreak begin',\n",
       " 'ftc accus mobil skim hundr million bogu charg',\n",
       " 'carri underwood miranda lambert plu cmt nomine face']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned data with no punctuations,stopwords and all texts in lowercase.\n",
    "cleaned[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1106, 4366,  692],\n",
       "       [   0,    0,    0, ..., 4618,  925, 3209],\n",
       "       [   0,    0,    0, ..., 2960,  806, 2055],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 2241, 1731, 3986],\n",
       "       [   0,    0,    0, ..., 4816, 2174,  631],\n",
       "       [   0,    0,    0, ..., 1336,  668, 2535]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking dictionary size 5000\n",
    "dict_size = 5000\n",
    "\n",
    "#one hot encoding\n",
    "one_hot_mat = [one_hot(words,dict_size) for words in cleaned]\n",
    "\n",
    "#now for input as an embedding layer length of all rows should be equal therefore applying padding\n",
    "#this will make size of all rows equal by adding 0 at starting of the shorter rows\n",
    "#size of each row will be equal to length of longest row.\n",
    "embedded_layer = pad_sequences(one_hot_mat,padding = 'pre',maxlen = 150)\n",
    "embedded_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now creating independent and dependent features\n",
    "x = embedded_layer\n",
    "y = np.array(ds['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#converting categorical values of y using OneHotEncoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = to_categorical(y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337935, 150) (337935, 4)\n",
      "(84484, 150) (84484, 4)\n"
     ]
    }
   ],
   "source": [
    "#splitting the Dataset into Train and Test set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 310,804\n",
      "Trainable params: 310,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1321/1321 [==============================] - 512s 387ms/step - loss: 0.3908 - accuracy: 0.8554 - val_loss: 0.2888 - val_accuracy: 0.8981\n",
      "Epoch 2/10\n",
      "1321/1321 [==============================] - 495s 374ms/step - loss: 0.2862 - accuracy: 0.8988 - val_loss: 0.2752 - val_accuracy: 0.9031\n",
      "Epoch 3/10\n",
      "1321/1321 [==============================] - 497s 376ms/step - loss: 0.2613 - accuracy: 0.9072 - val_loss: 0.2622 - val_accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "1321/1321 [==============================] - 510s 386ms/step - loss: 0.2445 - accuracy: 0.9128 - val_loss: 0.2558 - val_accuracy: 0.9094\n",
      "Epoch 5/10\n",
      "1321/1321 [==============================] - 497s 377ms/step - loss: 0.2320 - accuracy: 0.9175 - val_loss: 0.2520 - val_accuracy: 0.9111\n",
      "Epoch 6/10\n",
      "1321/1321 [==============================] - 497s 376ms/step - loss: 0.2214 - accuracy: 0.9210 - val_loss: 0.2481 - val_accuracy: 0.9133\n",
      "Epoch 7/10\n",
      "1321/1321 [==============================] - 799s 605ms/step - loss: 0.2108 - accuracy: 0.9247 - val_loss: 0.2438 - val_accuracy: 0.9147\n",
      "Epoch 8/10\n",
      "1321/1321 [==============================] - 821s 622ms/step - loss: 0.2000 - accuracy: 0.9287 - val_loss: 0.2457 - val_accuracy: 0.9159\n",
      "Epoch 9/10\n",
      "1321/1321 [==============================] - 828s 627ms/step - loss: 0.1905 - accuracy: 0.9314 - val_loss: 0.2413 - val_accuracy: 0.9179\n",
      "Epoch 10/10\n",
      "1321/1321 [==============================] - 833s 631ms/step - loss: 0.1815 - accuracy: 0.9349 - val_loss: 0.2410 - val_accuracy: 0.9182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d75517e940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating model using LSTM\n",
    "model = Sequential()\n",
    "\n",
    "#taking number features as 50\n",
    "model.add(Embedding(dict_size,50,input_length = len(x[0])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#adding LSTM layers with 100 neurons\n",
    "model.add(LSTM(100))\n",
    "\n",
    "#adding output layer \n",
    "model.add(Dense(4,activation=\"softmax\"))\n",
    "\n",
    "#compiling the model\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "\n",
    "#summary of model\n",
    "model.summary()\n",
    "\n",
    "#training the model\n",
    "model.fit(x_train, y_train, validation_data = (x_test,y_test), epochs = 10, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2641/2641 [==============================] - 120s 45ms/step - loss: 0.2410 - accuracy: 0.9182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24101004004478455, 0.9181738495826721]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating our model\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#making predictions\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "#saving index of maximum value of pred in preds (because in pred probabilities will come)\n",
    "preds = []\n",
    "for i in range(0,len(pred)):\n",
    "    preds.append(pred[i].argmax())\n",
    "\n",
    "#saving index of maximum value of y_test in actual\n",
    "actual = []\n",
    "for i in range(0,len(y_test)):\n",
    "    actual.append(y_test[i].argmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.90      0.90      0.90     23124\n",
      "           t       0.95      0.95      0.95     30536\n",
      "           e       0.91      0.88      0.89      9134\n",
      "           m       0.90      0.91      0.90     21690\n",
      "\n",
      "    accuracy                           0.92     84484\n",
      "   macro avg       0.91      0.91      0.91     84484\n",
      "weighted avg       0.92      0.92      0.92     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "from sklearn import metrics\n",
    "report = metrics.classification_report(actual, preds, target_names = ['b','t','e','m'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.3531038e-02 1.0842958e-03 2.0914743e-04 9.5517546e-01]] Health\n"
     ]
    }
   ],
   "source": [
    "#checking category of a text\n",
    "txt = [\"A soccer was eaten by Elvis Presley.\"]\n",
    "\n",
    "#cleaning and preprocessing the text\n",
    "cleaned = []\n",
    "for i in range(0,len(txt)):\n",
    "    msg = re.sub('[^a-zA-Z]',' ',txt[i])\n",
    "    msg = msg.lower()\n",
    "    msg = msg.split()\n",
    "    ps = PorterStemmer()\n",
    "    msg = [ps.stem(words) for words in msg if not words in set(stopwords.words('english'))]\n",
    "    msg = ' '.join(msg)\n",
    "    cleaned.append(msg)\n",
    "\n",
    "#one hot encoding and embedding layer\n",
    "one_hot_mat = [one_hot(words,dict_size) for words in cleaned]\n",
    "embedded_layer = pad_sequences(one_hot_mat,padding = 'pre',maxlen = 150)\n",
    "embedded_layer\n",
    "\n",
    "#prediction\n",
    "pred = model.predict(embedded_layer)\n",
    "cat = ['Business','Science','Entertainment','Health']\n",
    "print(pred, cat[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'weakref' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8a2c9cc61c80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpickle_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'weakref' object"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"model.pkl\",\"wb\")\n",
    "pickle.dump(model, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
